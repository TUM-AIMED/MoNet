{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "\n",
    "from preprocessing.data_loader import prepare_data\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "... preparing data\n",
      "... importing training data\n",
      "... importing labels \n",
      "  0%|          | 0/281 [00:00<?, ?it/s]... preparing training data and labels(seg)\n",
      "  0%|          | 0/281 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-d86c69a6d5eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m X_partial, y_partial_orig, X_val, y_val_orig, X_test, y_test_orig = prepare_data(\"/home/moritz/Data/Task07_Pancreas/\",\n\u001b[0m\u001b[1;32m      2\u001b[0m                                                                               \u001b[0mres\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                                                               \u001b[0mres_z\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m48\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                                                               \u001b[0mnum_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m281\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                                                               \u001b[0mmrg_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repositories/MoNet/preprocessing/data_loader.py\u001b[0m in \u001b[0;36mprepare_data\u001b[0;34m(path_string, res, res_z, num_samples, crop_height, mode, label_mode, mrg_labels)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0mcropped_scan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcropped_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrop_volume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrop_height\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcrop_height\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mcropped_scan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mcropped_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m         scan = resize(\n\u001b[0m\u001b[1;32m    254\u001b[0m             \u001b[0mcropped_scan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_z\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreserve_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         ).astype(np.float32)\n",
      "\u001b[0;32m~/miniconda3/envs/dev/lib/python3.8/site-packages/skimage/transform/_warps.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(image, output_shape, order, mode, cval, clip, preserve_range, anti_aliasing, anti_aliasing_sigma)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0mndi_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_to_ndimage_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m         out = ndi.map_coordinates(image, coord_map, order=order,\n\u001b[0m\u001b[1;32m    194\u001b[0m                                   mode=ndi_mode, cval=cval)\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dev/lib/python3.8/site-packages/scipy/ndimage/interpolation.py\u001b[0m in \u001b[0;36mmap_coordinates\u001b[0;34m(input, coordinates, output, order, mode, cval, prefilter)\u001b[0m\n\u001b[1;32m    388\u001b[0m     output = _ni_support._get_output(output, input,\n\u001b[1;32m    389\u001b[0m                                      shape=output_shape)\n\u001b[0;32m--> 390\u001b[0;31m     _nd_image.geometric_transform(filtered, None, coordinates, None, None,\n\u001b[0m\u001b[1;32m    391\u001b[0m                                   output, order, mode, cval, None, None)\n\u001b[1;32m    392\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X_partial, y_partial_orig, X_val, y_val_orig, X_test, y_test_orig = prepare_data(\"/home/moritz/Data/Task07_Pancreas/\",\n",
    "                                                                              res=256,\n",
    "                                                                              res_z=48,\n",
    "                                                                              num_samples=281,\n",
    "                                                                              mrg_labels=False,\n",
    "                                                                              label_mode='seg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#joblib.dump(y_test_orig, \"./serialized/data/y_test.lib\")\n",
    "X_partial = joblib.load(\"./serialized/data/x_partial.lib\")\n",
    "y_partial_orig = joblib.load(\"./serialized/data/y_partial.lib\")\n",
    "X_val = joblib.load(\"./serialized/data/x_val.lib\")\n",
    "y_val_orig = joblib.load(\"./serialized/data/y_val.lib\")\n",
    "X_test = joblib.load(\"./serialized/data/x_test.lib\")\n",
    "y_test_orig = joblib.load(\"./serialized/data/y_test.lib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((8448, 256, 256, 3), (960, 256, 256, 3), (4080, 256, 256, 3))"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "y_partial = tf.keras.utils.to_categorical(y_partial_orig, num_classes=3)\n",
    "y_val = tf.keras.utils.to_categorical(y_val_orig, num_classes=3)\n",
    "y_test = tf.keras.utils.to_categorical(y_test_orig, num_classes=3)\n",
    "y_partial.shape, y_val.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_partial_tumor = y_partial[..., 2]\n",
    "y_val_tumor = y_val[..., 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "b_size = 16\n",
    "def prep(inp): return inp\n",
    "\n",
    "data_gen_args = dict(\n",
    "rotation_range=10.,\n",
    "zoom_range=(0.8, 1.2),\n",
    "height_shift_range=0.2,\n",
    "width_shift_range=0.2,\n",
    "brightness_range=(0.7, 1.2),\n",
    "preprocessing_function=prep,\n",
    "rescale=1/255.)\n",
    "\n",
    "image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "mask_datagen = ImageDataGenerator(**data_gen_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "image_generator = image_datagen.flow(X_partial[..., None], seed=seed, batch_size=b_size)\n",
    "mask_generator = mask_datagen.flow(y_partial, seed=seed, batch_size=b_size)\n",
    "\n",
    "train_generator = zip(image_generator, mask_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coeff(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    y_true_f = tf.reshape(y_true, [-1])\n",
    "    y_pred_f = tf.reshape(y_pred, [-1])\n",
    "    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n",
    "    score = (2. * intersection + smooth) / (tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) + smooth)\n",
    "    return score\n",
    "\n",
    "def generalized_dice_loss(y_true, y_pred):\n",
    "    return 1-dice_coeff(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Segmentation Models: using `tf.keras` framework.\n"
     ]
    }
   ],
   "source": [
    "import segmentation_models as sm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from segmentation_models.metrics import f1_score\n",
    "\n",
    "def tumor_dice(y_true, y_pred):\n",
    "    return f1_score(y_true[..., 2], y_pred[..., 2])\n",
    "\n",
    "def panc_dice(y_true, y_pred):\n",
    "    return f1_score(y_true[..., 1], y_pred[..., 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.MoNet import getMoNet\n",
    "from models.custom_unet import custom_unet\n",
    "monet = getMoNet(output_classes=3)\n",
    "unet = custom_unet((256, 256, 1), num_classes=3, filters=64, output_activation='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = sm.FPN(input_shape=(256, 256, 3), classes=3, backbone_name='resnet50', encoder_weights='imagenet')\n",
    "inp = tf.keras.layers.Input(shape=(256, 256, 1))\n",
    "l1 = tf.keras.layers.Conv2D(3, (1, 1))(inp) # map N channels data to 3 channels\n",
    "out = base(l1)\n",
    "\n",
    "fpn = tf.keras.Model(inp, out, name=base.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_loss = sm.losses.DiceLoss() \n",
    "focal_loss = sm.losses.CategoricalFocalLoss()\n",
    "total_loss = dice_loss + (1 * focal_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "monet.compile(loss=dice_loss, optimizer='adam',\n",
    "              metrics=[\"accuracy\", tumor_dice, panc_dice, dice_coeff, tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "fpn.compile(loss=dice_loss, optimizer='adam',\n",
    "              metrics=[\"accuracy\", tumor_dice, panc_dice, dice_coeff, tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ss: 0.2677 - accuracy: 0.9976 - tumor_dice: 0.5690 - panc_dice: 0.6774 - dice_coeff: 0.9493 - precision: 0.9983 - recall: 0.9967 - val_loss: 0.3734 - val_accuracy: 0.9973 - val_tumor_dice: 0.1737 - val_panc_dice: 0.7072 - val_dice_coeff: 0.9973 - val_precision: 0.9973 - val_recall: 0.9973\n",
      "Epoch 37/90\n",
      "528/528 [==============================] - 114s 216ms/step - loss: 0.2621 - accuracy: 0.9977 - tumor_dice: 0.5764 - panc_dice: 0.6860 - dice_coeff: 0.9502 - precision: 0.9984 - recall: 0.9968 - val_loss: 0.3726 - val_accuracy: 0.9973 - val_tumor_dice: 0.1791 - val_panc_dice: 0.7044 - val_dice_coeff: 0.9973 - val_precision: 0.9973 - val_recall: 0.9973\n",
      "Epoch 38/90\n",
      "528/528 [==============================] - 114s 216ms/step - loss: 0.2588 - accuracy: 0.9978 - tumor_dice: 0.5835 - panc_dice: 0.6894 - dice_coeff: 0.9496 - precision: 0.9984 - recall: 0.9968 - val_loss: 0.3712 - val_accuracy: 0.9974 - val_tumor_dice: 0.1973 - val_panc_dice: 0.6905 - val_dice_coeff: 0.9974 - val_precision: 0.9974 - val_recall: 0.9974\n",
      "Epoch 39/90\n",
      "528/528 [==============================] - 114s 216ms/step - loss: 0.2582 - accuracy: 0.9977 - tumor_dice: 0.5879 - panc_dice: 0.6873 - dice_coeff: 0.9491 - precision: 0.9984 - recall: 0.9967 - val_loss: 0.3713 - val_accuracy: 0.9973 - val_tumor_dice: 0.1783 - val_panc_dice: 0.7090 - val_dice_coeff: 0.9973 - val_precision: 0.9973 - val_recall: 0.9973\n",
      "Epoch 40/90\n",
      "528/528 [==============================] - 115s 217ms/step - loss: 0.2726 - accuracy: 0.9976 - tumor_dice: 0.5527 - panc_dice: 0.6793 - dice_coeff: 0.9489 - precision: 0.9983 - recall: 0.9967 - val_loss: 0.3548 - val_accuracy: 0.9972 - val_tumor_dice: 0.2324 - val_panc_dice: 0.7044 - val_dice_coeff: 0.9972 - val_precision: 0.9972 - val_recall: 0.9972\n",
      "Epoch 41/90\n",
      "528/528 [==============================] - 114s 217ms/step - loss: 0.2612 - accuracy: 0.9977 - tumor_dice: 0.5791 - panc_dice: 0.6868 - dice_coeff: 0.9494 - precision: 0.9984 - recall: 0.9968 - val_loss: 0.3913 - val_accuracy: 0.9972 - val_tumor_dice: 0.1356 - val_panc_dice: 0.6918 - val_dice_coeff: 0.9972 - val_precision: 0.9972 - val_recall: 0.9972\n",
      "Epoch 42/90\n",
      "528/528 [==============================] - 115s 217ms/step - loss: 0.2593 - accuracy: 0.9977 - tumor_dice: 0.5899 - panc_dice: 0.6805 - dice_coeff: 0.9504 - precision: 0.9983 - recall: 0.9967 - val_loss: 0.3598 - val_accuracy: 0.9970 - val_tumor_dice: 0.2378 - val_panc_dice: 0.6842 - val_dice_coeff: 0.9970 - val_precision: 0.9970 - val_recall: 0.9970\n",
      "Epoch 43/90\n",
      "528/528 [==============================] - 114s 217ms/step - loss: 0.2561 - accuracy: 0.9978 - tumor_dice: 0.5890 - panc_dice: 0.6924 - dice_coeff: 0.9491 - precision: 0.9984 - recall: 0.9968 - val_loss: 0.3661 - val_accuracy: 0.9974 - val_tumor_dice: 0.1994 - val_panc_dice: 0.7036 - val_dice_coeff: 0.9974 - val_precision: 0.9974 - val_recall: 0.9974\n",
      "Epoch 44/90\n",
      "528/528 [==============================] - 115s 218ms/step - loss: 0.2492 - accuracy: 0.9978 - tumor_dice: 0.6031 - panc_dice: 0.6978 - dice_coeff: 0.9504 - precision: 0.9985 - recall: 0.9968 - val_loss: 0.3687 - val_accuracy: 0.9972 - val_tumor_dice: 0.2036 - val_panc_dice: 0.6916 - val_dice_coeff: 0.9972 - val_precision: 0.9972 - val_recall: 0.9972\n",
      "Epoch 45/90\n",
      "528/528 [==============================] - 115s 217ms/step - loss: 0.2482 - accuracy: 0.9978 - tumor_dice: 0.6094 - panc_dice: 0.6946 - dice_coeff: 0.9503 - precision: 0.9985 - recall: 0.9968 - val_loss: 0.3667 - val_accuracy: 0.9975 - val_tumor_dice: 0.1890 - val_panc_dice: 0.7121 - val_dice_coeff: 0.9975 - val_precision: 0.9975 - val_recall: 0.9975\n",
      "Epoch 46/90\n",
      "528/528 [==============================] - 115s 217ms/step - loss: 0.2503 - accuracy: 0.9978 - tumor_dice: 0.6016 - panc_dice: 0.6963 - dice_coeff: 0.9501 - precision: 0.9985 - recall: 0.9969 - val_loss: 0.3864 - val_accuracy: 0.9975 - val_tumor_dice: 0.1352 - val_panc_dice: 0.7067 - val_dice_coeff: 0.9974 - val_precision: 0.9975 - val_recall: 0.9975\n",
      "Epoch 47/90\n",
      "528/528 [==============================] - 114s 216ms/step - loss: 0.2475 - accuracy: 0.9978 - tumor_dice: 0.6099 - panc_dice: 0.6966 - dice_coeff: 0.9498 - precision: 0.9985 - recall: 0.9969 - val_loss: 0.3622 - val_accuracy: 0.9974 - val_tumor_dice: 0.2013 - val_panc_dice: 0.7133 - val_dice_coeff: 0.9973 - val_precision: 0.9974 - val_recall: 0.9974\n",
      "Epoch 48/90\n",
      "528/528 [==============================] - 114s 216ms/step - loss: 0.2510 - accuracy: 0.9977 - tumor_dice: 0.6035 - panc_dice: 0.6916 - dice_coeff: 0.9507 - precision: 0.9984 - recall: 0.9968 - val_loss: 0.3818 - val_accuracy: 0.9970 - val_tumor_dice: 0.1899 - val_panc_dice: 0.6661 - val_dice_coeff: 0.9970 - val_precision: 0.9970 - val_recall: 0.9970\n",
      "Epoch 49/90\n",
      "528/528 [==============================] - 114s 216ms/step - loss: 0.2463 - accuracy: 0.9978 - tumor_dice: 0.6147 - panc_dice: 0.6938 - dice_coeff: 0.9512 - precision: 0.9984 - recall: 0.9968 - val_loss: 0.3525 - val_accuracy: 0.9973 - val_tumor_dice: 0.2358 - val_panc_dice: 0.7078 - val_dice_coeff: 0.9973 - val_precision: 0.9973 - val_recall: 0.9973\n",
      "Epoch 50/90\n",
      "528/528 [==============================] - 114s 216ms/step - loss: 0.2504 - accuracy: 0.9978 - tumor_dice: 0.6019 - panc_dice: 0.6958 - dice_coeff: 0.9499 - precision: 0.9985 - recall: 0.9968 - val_loss: 0.3564 - val_accuracy: 0.9975 - val_tumor_dice: 0.2161 - val_panc_dice: 0.7158 - val_dice_coeff: 0.9975 - val_precision: 0.9975 - val_recall: 0.9975\n",
      "Epoch 51/90\n",
      "528/528 [==============================] - 114s 217ms/step - loss: 0.2424 - accuracy: 0.9979 - tumor_dice: 0.6234 - panc_dice: 0.6989 - dice_coeff: 0.9494 - precision: 0.9985 - recall: 0.9969 - val_loss: 0.3602 - val_accuracy: 0.9972 - val_tumor_dice: 0.2069 - val_panc_dice: 0.7136 - val_dice_coeff: 0.9972 - val_precision: 0.9972 - val_recall: 0.9972\n",
      "Epoch 52/90\n",
      "528/528 [==============================] - 115s 218ms/step - loss: 0.2359 - accuracy: 0.9979 - tumor_dice: 0.6344 - panc_dice: 0.7057 - dice_coeff: 0.9510 - precision: 0.9986 - recall: 0.9969 - val_loss: 0.3567 - val_accuracy: 0.9975 - val_tumor_dice: 0.2156 - val_panc_dice: 0.7155 - val_dice_coeff: 0.9975 - val_precision: 0.9975 - val_recall: 0.9975\n",
      "Epoch 53/90\n",
      "528/528 [==============================] - 114s 216ms/step - loss: 0.2375 - accuracy: 0.9979 - tumor_dice: 0.6346 - panc_dice: 0.7017 - dice_coeff: 0.9503 - precision: 0.9985 - recall: 0.9969 - val_loss: 0.3542 - val_accuracy: 0.9975 - val_tumor_dice: 0.2182 - val_panc_dice: 0.7204 - val_dice_coeff: 0.9975 - val_precision: 0.9975 - val_recall: 0.9975\n",
      "Epoch 54/90\n",
      "528/528 [==============================] - 115s 217ms/step - loss: 0.2374 - accuracy: 0.9979 - tumor_dice: 0.6347 - panc_dice: 0.7034 - dice_coeff: 0.9485 - precision: 0.9986 - recall: 0.9969 - val_loss: 0.3561 - val_accuracy: 0.9974 - val_tumor_dice: 0.2162 - val_panc_dice: 0.7169 - val_dice_coeff: 0.9974 - val_precision: 0.9974 - val_recall: 0.9974\n",
      "Epoch 55/90\n",
      "528/528 [==============================] - 115s 217ms/step - loss: 0.2444 - accuracy: 0.9979 - tumor_dice: 0.6146 - panc_dice: 0.7022 - dice_coeff: 0.9490 - precision: 0.9985 - recall: 0.9969 - val_loss: 0.3564 - val_accuracy: 0.9973 - val_tumor_dice: 0.2180 - val_panc_dice: 0.7138 - val_dice_coeff: 0.9973 - val_precision: 0.9973 - val_recall: 0.9973\n",
      "Epoch 56/90\n",
      "528/528 [==============================] - 114s 216ms/step - loss: 0.2432 - accuracy: 0.9979 - tumor_dice: 0.6192 - panc_dice: 0.6998 - dice_coeff: 0.9503 - precision: 0.9985 - recall: 0.9969 - val_loss: 0.3556 - val_accuracy: 0.9972 - val_tumor_dice: 0.2373 - val_panc_dice: 0.6972 - val_dice_coeff: 0.9972 - val_precision: 0.9972 - val_recall: 0.9972\n",
      "Epoch 57/90\n",
      "528/528 [==============================] - 114s 216ms/step - loss: 0.2424 - accuracy: 0.9979 - tumor_dice: 0.6185 - panc_dice: 0.7028 - dice_coeff: 0.9504 - precision: 0.9985 - recall: 0.9969 - val_loss: 0.3925 - val_accuracy: 0.9965 - val_tumor_dice: 0.1607 - val_panc_dice: 0.6633 - val_dice_coeff: 0.9965 - val_precision: 0.9965 - val_recall: 0.9965\n",
      "Epoch 58/90\n",
      "528/528 [==============================] - 115s 218ms/step - loss: 0.2361 - accuracy: 0.9979 - tumor_dice: 0.6384 - panc_dice: 0.7022 - dice_coeff: 0.9499 - precision: 0.9985 - recall: 0.9969 - val_loss: 0.3749 - val_accuracy: 0.9975 - val_tumor_dice: 0.1559 - val_panc_dice: 0.7205 - val_dice_coeff: 0.9975 - val_precision: 0.9975 - val_recall: 0.9975\n",
      "Epoch 59/90\n",
      "528/528 [==============================] - 114s 216ms/step - loss: 0.2304 - accuracy: 0.9980 - tumor_dice: 0.6475 - panc_dice: 0.7113 - dice_coeff: 0.9489 - precision: 0.9986 - recall: 0.9970 - val_loss: 0.3674 - val_accuracy: 0.9974 - val_tumor_dice: 0.1877 - val_panc_dice: 0.7112 - val_dice_coeff: 0.9974 - val_precision: 0.9974 - val_recall: 0.9974\n",
      "Epoch 60/90\n",
      "528/528 [==============================] - 114s 217ms/step - loss: 0.2455 - accuracy: 0.9978 - tumor_dice: 0.6090 - panc_dice: 0.7021 - dice_coeff: 0.9512 - precision: 0.9985 - recall: 0.9969 - val_loss: 0.3498 - val_accuracy: 0.9975 - val_tumor_dice: 0.2440 - val_panc_dice: 0.7077 - val_dice_coeff: 0.9975 - val_precision: 0.9975 - val_recall: 0.9975\n",
      "Epoch 61/90\n",
      "528/528 [==============================] - 114s 215ms/step - loss: 0.2281 - accuracy: 0.9979 - tumor_dice: 0.6542 - panc_dice: 0.7103 - dice_coeff: 0.9502 - precision: 0.9986 - recall: 0.9970 - val_loss: 0.3701 - val_accuracy: 0.9975 - val_tumor_dice: 0.1705 - val_panc_dice: 0.7204 - val_dice_coeff: 0.9975 - val_precision: 0.9975 - val_recall: 0.9975\n",
      "Epoch 62/90\n",
      "528/528 [==============================] - 114s 216ms/step - loss: 0.2296 - accuracy: 0.9980 - tumor_dice: 0.6427 - panc_dice: 0.7170 - dice_coeff: 0.9504 - precision: 0.9986 - recall: 0.9970 - val_loss: 0.3695 - val_accuracy: 0.9975 - val_tumor_dice: 0.1655 - val_panc_dice: 0.7269 - val_dice_coeff: 0.9975 - val_precision: 0.9975 - val_recall: 0.9975\n",
      "Epoch 63/90\n",
      "528/528 [==============================] - 114s 216ms/step - loss: 0.2344 - accuracy: 0.9979 - tumor_dice: 0.6401 - panc_dice: 0.7053 - dice_coeff: 0.9502 - precision: 0.9986 - recall: 0.9970 - val_loss: 0.3833 - val_accuracy: 0.9972 - val_tumor_dice: 0.1437 - val_panc_dice: 0.7076 - val_dice_coeff: 0.9972 - val_precision: 0.9972 - val_recall: 0.9972\n",
      "Epoch 64/90\n",
      "528/528 [==============================] - 114s 216ms/step - loss: 0.2257 - accuracy: 0.9980 - tumor_dice: 0.6536 - panc_dice: 0.7183 - dice_coeff: 0.9499 - precision: 0.9987 - recall: 0.9970 - val_loss: 0.3718 - val_accuracy: 0.9975 - val_tumor_dice: 0.1657 - val_panc_dice: 0.7200 - val_dice_coeff: 0.9975 - val_precision: 0.9975 - val_recall: 0.9975\n",
      "Epoch 65/90\n",
      "528/528 [==============================] - 115s 217ms/step - loss: 0.2271 - accuracy: 0.9980 - tumor_dice: 0.6538 - panc_dice: 0.7146 - dice_coeff: 0.9492 - precision: 0.9986 - recall: 0.9970 - val_loss: 0.3619 - val_accuracy: 0.9973 - val_tumor_dice: 0.1977 - val_panc_dice: 0.7178 - val_dice_coeff: 0.9973 - val_precision: 0.9973 - val_recall: 0.9973\n",
      "Epoch 66/90\n",
      "528/528 [==============================] - 115s 217ms/step - loss: 0.2250 - accuracy: 0.9980 - tumor_dice: 0.6591 - panc_dice: 0.7149 - dice_coeff: 0.9501 - precision: 0.9987 - recall: 0.9970 - val_loss: 0.4050 - val_accuracy: 0.9971 - val_tumor_dice: 0.1456 - val_panc_dice: 0.6409 - val_dice_coeff: 0.9970 - val_precision: 0.9971 - val_recall: 0.9971\n",
      "Epoch 67/90\n",
      "528/528 [==============================] - 115s 217ms/step - loss: 0.2359 - accuracy: 0.9979 - tumor_dice: 0.6363 - panc_dice: 0.7057 - dice_coeff: 0.9492 - precision: 0.9986 - recall: 0.9969 - val_loss: 0.3594 - val_accuracy: 0.9974 - val_tumor_dice: 0.2058 - val_panc_dice: 0.7173 - val_dice_coeff: 0.9974 - val_precision: 0.9974 - val_recall: 0.9974\n",
      "Epoch 68/90\n",
      "528/528 [==============================] - 115s 217ms/step - loss: 0.2252 - accuracy: 0.9980 - tumor_dice: 0.6571 - panc_dice: 0.7169 - dice_coeff: 0.9494 - precision: 0.9987 - recall: 0.9971 - val_loss: 0.3569 - val_accuracy: 0.9974 - val_tumor_dice: 0.2122 - val_panc_dice: 0.7183 - val_dice_coeff: 0.9974 - val_precision: 0.9974 - val_recall: 0.9974\n",
      "Epoch 69/90\n",
      "528/528 [==============================] - 114s 216ms/step - loss: 0.2246 - accuracy: 0.9980 - tumor_dice: 0.6611 - panc_dice: 0.7137 - dice_coeff: 0.9506 - precision: 0.9986 - recall: 0.9970 - val_loss: 0.3687 - val_accuracy: 0.9975 - val_tumor_dice: 0.1726 - val_panc_dice: 0.7226 - val_dice_coeff: 0.9975 - val_precision: 0.9975 - val_recall: 0.9975\n",
      "Epoch 70/90\n",
      "528/528 [==============================] - 114s 216ms/step - loss: 0.2222 - accuracy: 0.9980 - tumor_dice: 0.6635 - panc_dice: 0.7185 - dice_coeff: 0.9503 - precision: 0.9987 - recall: 0.9970 - val_loss: 0.3718 - val_accuracy: 0.9975 - val_tumor_dice: 0.1613 - val_panc_dice: 0.7246 - val_dice_coeff: 0.9975 - val_precision: 0.9975 - val_recall: 0.9975\n",
      "Epoch 71/90\n",
      "528/528 [==============================] - 114s 217ms/step - loss: 0.2170 - accuracy: 0.9980 - tumor_dice: 0.6773 - panc_dice: 0.7203 - dice_coeff: 0.9503 - precision: 0.9987 - recall: 0.9971 - val_loss: 0.3711 - val_accuracy: 0.9975 - val_tumor_dice: 0.1638 - val_panc_dice: 0.7240 - val_dice_coeff: 0.9975 - val_precision: 0.9975 - val_recall: 0.9975\n",
      "Epoch 72/90\n",
      "528/528 [==============================] - 115s 218ms/step - loss: 0.2220 - accuracy: 0.9981 - tumor_dice: 0.6623 - panc_dice: 0.7205 - dice_coeff: 0.9501 - precision: 0.9987 - recall: 0.9971 - val_loss: 0.3660 - val_accuracy: 0.9975 - val_tumor_dice: 0.1945 - val_panc_dice: 0.7086 - val_dice_coeff: 0.9975 - val_precision: 0.9975 - val_recall: 0.9975\n",
      "Epoch 73/90\n",
      "528/528 [==============================] - 115s 217ms/step - loss: 0.2338 - accuracy: 0.9979 - tumor_dice: 0.6468 - panc_dice: 0.7017 - dice_coeff: 0.9491 - precision: 0.9985 - recall: 0.9969 - val_loss: 0.3822 - val_accuracy: 0.9974 - val_tumor_dice: 0.1478 - val_panc_dice: 0.7069 - val_dice_coeff: 0.9974 - val_precision: 0.9974 - val_recall: 0.9974\n",
      "Epoch 74/90\n",
      "528/528 [==============================] - 114s 216ms/step - loss: 0.2298 - accuracy: 0.9980 - tumor_dice: 0.6424 - panc_dice: 0.7170 - dice_coeff: 0.9502 - precision: 0.9986 - recall: 0.9970 - val_loss: 0.3729 - val_accuracy: 0.9974 - val_tumor_dice: 0.1665 - val_panc_dice: 0.7159 - val_dice_coeff: 0.9974 - val_precision: 0.9974 - val_recall: 0.9974\n",
      "Epoch 75/90\n",
      "528/528 [==============================] - 114s 216ms/step - loss: 0.2111 - accuracy: 0.9981 - tumor_dice: 0.6885 - panc_dice: 0.7267 - dice_coeff: 0.9506 - precision: 0.9988 - recall: 0.9971 - val_loss: 0.3644 - val_accuracy: 0.9975 - val_tumor_dice: 0.1877 - val_panc_dice: 0.7202 - val_dice_coeff: 0.9975 - val_precision: 0.9975 - val_recall: 0.9975\n",
      "Epoch 76/90\n",
      "528/528 [==============================] - 115s 217ms/step - loss: 0.2170 - accuracy: 0.9981 - tumor_dice: 0.6719 - panc_dice: 0.7254 - dice_coeff: 0.9506 - precision: 0.9987 - recall: 0.9971 - val_loss: 0.3715 - val_accuracy: 0.9974 - val_tumor_dice: 0.1718 - val_panc_dice: 0.7150 - val_dice_coeff: 0.9974 - val_precision: 0.9974 - val_recall: 0.9974\n",
      "Epoch 77/90\n",
      "528/528 [==============================] - 115s 217ms/step - loss: 0.2158 - accuracy: 0.9981 - tumor_dice: 0.6788 - panc_dice: 0.7225 - dice_coeff: 0.9502 - precision: 0.9987 - recall: 0.9971 - val_loss: 0.3717 - val_accuracy: 0.9975 - val_tumor_dice: 0.1689 - val_panc_dice: 0.7172 - val_dice_coeff: 0.9975 - val_precision: 0.9975 - val_recall: 0.9975\n",
      "Epoch 78/90\n",
      "528/528 [==============================] - 114s 216ms/step - loss: 0.2144 - accuracy: 0.9981 - tumor_dice: 0.6809 - panc_dice: 0.7237 - dice_coeff: 0.9511 - precision: 0.9987 - recall: 0.9971 - val_loss: 0.3604 - val_accuracy: 0.9974 - val_tumor_dice: 0.2081 - val_panc_dice: 0.7118 - val_dice_coeff: 0.9974 - val_precision: 0.9974 - val_recall: 0.9974\n",
      "Epoch 79/90\n",
      "528/528 [==============================] - 114s 217ms/step - loss: 0.2190 - accuracy: 0.9980 - tumor_dice: 0.6713 - panc_dice: 0.7203 - dice_coeff: 0.9503 - precision: 0.9987 - recall: 0.9970 - val_loss: 0.3740 - val_accuracy: 0.9973 - val_tumor_dice: 0.1756 - val_panc_dice: 0.7037 - val_dice_coeff: 0.9973 - val_precision: 0.9973 - val_recall: 0.9973\n",
      "Epoch 80/90\n",
      "528/528 [==============================] - 115s 218ms/step - loss: 0.2254 - accuracy: 0.9980 - tumor_dice: 0.6600 - panc_dice: 0.7122 - dice_coeff: 0.9506 - precision: 0.9986 - recall: 0.9970 - val_loss: 0.3623 - val_accuracy: 0.9975 - val_tumor_dice: 0.1904 - val_panc_dice: 0.7237 - val_dice_coeff: 0.9975 - val_precision: 0.9975 - val_recall: 0.9975\n",
      "Epoch 81/90\n",
      "528/528 [==============================] - 115s 217ms/step - loss: 0.2164 - accuracy: 0.9981 - tumor_dice: 0.6779 - panc_dice: 0.7227 - dice_coeff: 0.9492 - precision: 0.9987 - recall: 0.9971 - val_loss: 0.3658 - val_accuracy: 0.9975 - val_tumor_dice: 0.1821 - val_panc_dice: 0.7217 - val_dice_coeff: 0.9975 - val_precision: 0.9975 - val_recall: 0.9975\n",
      "Epoch 82/90\n",
      "528/528 [==============================] - 114s 216ms/step - loss: 0.2099 - accuracy: 0.9981 - tumor_dice: 0.6870 - panc_dice: 0.7313 - dice_coeff: 0.9508 - precision: 0.9988 - recall: 0.9971 - val_loss: 0.3644 - val_accuracy: 0.9975 - val_tumor_dice: 0.1963 - val_panc_dice: 0.7115 - val_dice_coeff: 0.9975 - val_precision: 0.9975 - val_recall: 0.9975\n",
      "Epoch 83/90\n",
      "528/528 [==============================] - 115s 217ms/step - loss: 0.2134 - accuracy: 0.9981 - tumor_dice: 0.6782 - panc_dice: 0.7301 - dice_coeff: 0.9506 - precision: 0.9988 - recall: 0.9971 - val_loss: 0.3781 - val_accuracy: 0.9970 - val_tumor_dice: 0.1794 - val_panc_dice: 0.6877 - val_dice_coeff: 0.9969 - val_precision: 0.9970 - val_recall: 0.9970\n",
      "Epoch 84/90\n",
      "528/528 [==============================] - 115s 217ms/step - loss: 0.2090 - accuracy: 0.9981 - tumor_dice: 0.6884 - panc_dice: 0.7316 - dice_coeff: 0.9520 - precision: 0.9988 - recall: 0.9972 - val_loss: 0.3854 - val_accuracy: 0.9972 - val_tumor_dice: 0.1461 - val_panc_dice: 0.6991 - val_dice_coeff: 0.9972 - val_precision: 0.9972 - val_recall: 0.9972\n",
      "Epoch 85/90\n",
      "528/528 [==============================] - 114s 217ms/step - loss: 0.2183 - accuracy: 0.9981 - tumor_dice: 0.6690 - panc_dice: 0.7244 - dice_coeff: 0.9507 - precision: 0.9987 - recall: 0.9971 - val_loss: 0.3768 - val_accuracy: 0.9972 - val_tumor_dice: 0.1814 - val_panc_dice: 0.6895 - val_dice_coeff: 0.9972 - val_precision: 0.9972 - val_recall: 0.9972\n",
      "Epoch 86/90\n",
      "528/528 [==============================] - 115s 217ms/step - loss: 0.2231 - accuracy: 0.9980 - tumor_dice: 0.6663 - panc_dice: 0.7139 - dice_coeff: 0.9496 - precision: 0.9986 - recall: 0.9970 - val_loss: 0.3727 - val_accuracy: 0.9976 - val_tumor_dice: 0.1712 - val_panc_dice: 0.7119 - val_dice_coeff: 0.9976 - val_precision: 0.9976 - val_recall: 0.9976\n",
      "Epoch 87/90\n",
      "528/528 [==============================] - 115s 217ms/step - loss: 0.2122 - accuracy: 0.9981 - tumor_dice: 0.6849 - panc_dice: 0.7276 - dice_coeff: 0.9500 - precision: 0.9988 - recall: 0.9971 - val_loss: 0.3720 - val_accuracy: 0.9975 - val_tumor_dice: 0.1652 - val_panc_dice: 0.7198 - val_dice_coeff: 0.9975 - val_precision: 0.9975 - val_recall: 0.9975\n",
      "Epoch 88/90\n",
      "528/528 [==============================] - 114s 217ms/step - loss: 0.2059 - accuracy: 0.9981 - tumor_dice: 0.6980 - panc_dice: 0.7324 - dice_coeff: 0.9510 - precision: 0.9988 - recall: 0.9972 - val_loss: 0.4202 - val_accuracy: 0.9965 - val_tumor_dice: 0.1135 - val_panc_dice: 0.6276 - val_dice_coeff: 0.9965 - val_precision: 0.9965 - val_recall: 0.9965\n",
      "Epoch 89/90\n",
      "528/528 [==============================] - 115s 217ms/step - loss: 0.2301 - accuracy: 0.9979 - tumor_dice: 0.6544 - panc_dice: 0.7043 - dice_coeff: 0.9501 - precision: 0.9985 - recall: 0.9969 - val_loss: 0.3740 - val_accuracy: 0.9973 - val_tumor_dice: 0.1850 - val_panc_dice: 0.6942 - val_dice_coeff: 0.9973 - val_precision: 0.9973 - val_recall: 0.9973\n",
      "Epoch 90/90\n",
      "528/528 [==============================] - 115s 217ms/step - loss: 0.2080 - accuracy: 0.9981 - tumor_dice: 0.6942 - panc_dice: 0.7307 - dice_coeff: 0.9502 - precision: 0.9988 - recall: 0.9972 - val_loss: 0.3610 - val_accuracy: 0.9975 - val_tumor_dice: 0.1940 - val_panc_dice: 0.7243 - val_dice_coeff: 0.9974 - val_precision: 0.9975 - val_recall: 0.9975\n"
     ]
    }
   ],
   "source": [
    "history = monet.fit(\n",
    "          train_generator,\n",
    "          validation_data=(X_val[..., None], y_val),\n",
    "          steps_per_epoch=X_partial.shape[0]//b_size,\n",
    "          epochs=90,\n",
    "          callbacks=[],\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "monet.save_weights(\"./serialized/weights/monet_panc+tumor_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "========================] - 134s 255ms/step - loss: 0.2475 - accuracy: 0.9979 - tumor_dice: 0.5947 - panc_dice: 0.7112 - dice_coeff: 0.9504 - precision_3: 0.9986 - recall_3: 0.9969 - val_loss: 0.3430 - val_accuracy: 0.9968 - val_tumor_dice: 0.4074 - val_panc_dice: 0.5650 - val_dice_coeff: 0.9968 - val_precision_3: 0.9968 - val_recall_3: 0.9968\n",
      "Epoch 51/200\n",
      "528/528 [==============================] - 134s 254ms/step - loss: 0.2572 - accuracy: 0.9979 - tumor_dice: 0.5730 - panc_dice: 0.7056 - dice_coeff: 0.9486 - precision_3: 0.9985 - recall_3: 0.9969 - val_loss: 0.4048 - val_accuracy: 0.9961 - val_tumor_dice: 0.3561 - val_panc_dice: 0.4313 - val_dice_coeff: 0.9961 - val_precision_3: 0.9961 - val_recall_3: 0.9961\n",
      "Epoch 52/200\n",
      "528/528 [==============================] - 134s 254ms/step - loss: 0.2502 - accuracy: 0.9979 - tumor_dice: 0.5872 - panc_dice: 0.7119 - dice_coeff: 0.9491 - precision_3: 0.9986 - recall_3: 0.9970 - val_loss: 0.2846 - val_accuracy: 0.9973 - val_tumor_dice: 0.4947 - val_panc_dice: 0.6528 - val_dice_coeff: 0.9973 - val_precision_3: 0.9973 - val_recall_3: 0.9973\n",
      "Epoch 53/200\n",
      "528/528 [==============================] - 134s 254ms/step - loss: 0.2471 - accuracy: 0.9980 - tumor_dice: 0.5914 - panc_dice: 0.7163 - dice_coeff: 0.9501 - precision_3: 0.9986 - recall_3: 0.9970 - val_loss: 0.3638 - val_accuracy: 0.9969 - val_tumor_dice: 0.3590 - val_panc_dice: 0.5510 - val_dice_coeff: 0.9969 - val_precision_3: 0.9969 - val_recall_3: 0.9969\n",
      "Epoch 54/200\n",
      "528/528 [==============================] - 134s 254ms/step - loss: 0.2454 - accuracy: 0.9980 - tumor_dice: 0.5929 - panc_dice: 0.7193 - dice_coeff: 0.9505 - precision_3: 0.9986 - recall_3: 0.9970 - val_loss: 0.4845 - val_accuracy: 0.9939 - val_tumor_dice: 0.1679 - val_panc_dice: 0.3814 - val_dice_coeff: 0.9939 - val_precision_3: 0.9939 - val_recall_3: 0.9939\n",
      "Epoch 55/200\n",
      "528/528 [==============================] - 134s 254ms/step - loss: 0.2545 - accuracy: 0.9979 - tumor_dice: 0.5802 - panc_dice: 0.7053 - dice_coeff: 0.9499 - precision_3: 0.9985 - recall_3: 0.9969 - val_loss: 0.3322 - val_accuracy: 0.9973 - val_tumor_dice: 0.3290 - val_panc_dice: 0.6755 - val_dice_coeff: 0.9973 - val_precision_3: 0.9973 - val_recall_3: 0.9973\n",
      "Epoch 56/200\n",
      "528/528 [==============================] - 134s 255ms/step - loss: 0.2417 - accuracy: 0.9980 - tumor_dice: 0.6038 - panc_dice: 0.7214 - dice_coeff: 0.9489 - precision_3: 0.9987 - recall_3: 0.9970 - val_loss: 0.3331 - val_accuracy: 0.9967 - val_tumor_dice: 0.3371 - val_panc_dice: 0.6652 - val_dice_coeff: 0.9967 - val_precision_3: 0.9967 - val_recall_3: 0.9967\n",
      "Epoch 57/200\n",
      "528/528 [==============================] - 134s 254ms/step - loss: 0.2367 - accuracy: 0.9980 - tumor_dice: 0.6146 - panc_dice: 0.7228 - dice_coeff: 0.9514 - precision_3: 0.9987 - recall_3: 0.9970 - val_loss: 0.2954 - val_accuracy: 0.9972 - val_tumor_dice: 0.4422 - val_panc_dice: 0.6729 - val_dice_coeff: 0.9972 - val_precision_3: 0.9972 - val_recall_3: 0.9972\n",
      "Epoch 58/200\n",
      "528/528 [==============================] - 134s 255ms/step - loss: 0.2350 - accuracy: 0.9980 - tumor_dice: 0.6182 - panc_dice: 0.7255 - dice_coeff: 0.9504 - precision_3: 0.9987 - recall_3: 0.9971 - val_loss: 0.2970 - val_accuracy: 0.9970 - val_tumor_dice: 0.4375 - val_panc_dice: 0.6727 - val_dice_coeff: 0.9970 - val_precision_3: 0.9970 - val_recall_3: 0.9970\n",
      "Epoch 59/200\n",
      "528/528 [==============================] - 135s 255ms/step - loss: 0.2389 - accuracy: 0.9981 - tumor_dice: 0.6050 - panc_dice: 0.7269 - dice_coeff: 0.9504 - precision_3: 0.9987 - recall_3: 0.9971 - val_loss: 0.3662 - val_accuracy: 0.9968 - val_tumor_dice: 0.3552 - val_panc_dice: 0.5478 - val_dice_coeff: 0.9968 - val_precision_3: 0.9968 - val_recall_3: 0.9968\n",
      "Epoch 60/200\n",
      "528/528 [==============================] - 134s 254ms/step - loss: 0.2514 - accuracy: 0.9979 - tumor_dice: 0.5867 - panc_dice: 0.7081 - dice_coeff: 0.9501 - precision_3: 0.9986 - recall_3: 0.9969 - val_loss: 0.3037 - val_accuracy: 0.9973 - val_tumor_dice: 0.4230 - val_panc_dice: 0.6670 - val_dice_coeff: 0.9973 - val_precision_3: 0.9973 - val_recall_3: 0.9973\n",
      "Epoch 61/200\n",
      "528/528 [==============================] - 134s 254ms/step - loss: 0.2352 - accuracy: 0.9980 - tumor_dice: 0.6180 - panc_dice: 0.7255 - dice_coeff: 0.9499 - precision_3: 0.9987 - recall_3: 0.9970 - val_loss: 0.3538 - val_accuracy: 0.9970 - val_tumor_dice: 0.3184 - val_panc_dice: 0.6215 - val_dice_coeff: 0.9970 - val_precision_3: 0.9970 - val_recall_3: 0.9970\n",
      "Epoch 62/200\n",
      "528/528 [==============================] - 134s 254ms/step - loss: 0.2339 - accuracy: 0.9981 - tumor_dice: 0.6197 - panc_dice: 0.7284 - dice_coeff: 0.9493 - precision_3: 0.9987 - recall_3: 0.9971 - val_loss: 0.3220 - val_accuracy: 0.9970 - val_tumor_dice: 0.3757 - val_panc_dice: 0.6595 - val_dice_coeff: 0.9970 - val_precision_3: 0.9970 - val_recall_3: 0.9970\n",
      "Epoch 63/200\n",
      "528/528 [==============================] - 134s 254ms/step - loss: 0.2398 - accuracy: 0.9980 - tumor_dice: 0.6068 - panc_dice: 0.7227 - dice_coeff: 0.9500 - precision_3: 0.9987 - recall_3: 0.9970 - val_loss: 0.3265 - val_accuracy: 0.9972 - val_tumor_dice: 0.3616 - val_panc_dice: 0.6602 - val_dice_coeff: 0.9972 - val_precision_3: 0.9972 - val_recall_3: 0.9972\n",
      "Epoch 64/200\n",
      "528/528 [==============================] - 134s 254ms/step - loss: 0.2402 - accuracy: 0.9981 - tumor_dice: 0.6037 - panc_dice: 0.7255 - dice_coeff: 0.9492 - precision_3: 0.9987 - recall_3: 0.9971 - val_loss: 0.3527 - val_accuracy: 0.9966 - val_tumor_dice: 0.4602 - val_panc_dice: 0.4835 - val_dice_coeff: 0.9966 - val_precision_3: 0.9966 - val_recall_3: 0.9966\n",
      "Epoch 65/200\n",
      "528/528 [==============================] - 134s 254ms/step - loss: 0.2549 - accuracy: 0.9979 - tumor_dice: 0.5744 - panc_dice: 0.7100 - dice_coeff: 0.9497 - precision_3: 0.9985 - recall_3: 0.9969 - val_loss: 0.3084 - val_accuracy: 0.9973 - val_tumor_dice: 0.4014 - val_panc_dice: 0.6745 - val_dice_coeff: 0.9973 - val_precision_3: 0.9973 - val_recall_3: 0.9973\n",
      "Epoch 66/200\n",
      "528/528 [==============================] - 134s 254ms/step - loss: 0.2368 - accuracy: 0.9981 - tumor_dice: 0.6146 - panc_dice: 0.7239 - dice_coeff: 0.9500 - precision_3: 0.9987 - recall_3: 0.9971 - val_loss: 0.2976 - val_accuracy: 0.9972 - val_tumor_dice: 0.4299 - val_panc_dice: 0.6787 - val_dice_coeff: 0.9972 - val_precision_3: 0.9972 - val_recall_3: 0.9972\n",
      "Epoch 67/200\n",
      "528/528 [==============================] - 134s 254ms/step - loss: 0.2342 - accuracy: 0.9981 - tumor_dice: 0.6166 - panc_dice: 0.7295 - dice_coeff: 0.9505 - precision_3: 0.9987 - recall_3: 0.9971 - val_loss: 0.3094 - val_accuracy: 0.9973 - val_tumor_dice: 0.4010 - val_panc_dice: 0.6721 - val_dice_coeff: 0.9973 - val_precision_3: 0.9973 - val_recall_3: 0.9973\n",
      "Epoch 68/200\n",
      "528/528 [==============================] - 134s 254ms/step - loss: 0.2250 - accuracy: 0.9981 - tumor_dice: 0.6357 - panc_dice: 0.7379 - dice_coeff: 0.9505 - precision_3: 0.9988 - recall_3: 0.9972 - val_loss: 0.3096 - val_accuracy: 0.9973 - val_tumor_dice: 0.4020 - val_panc_dice: 0.6704 - val_dice_coeff: 0.9973 - val_precision_3: 0.9973 - val_recall_3: 0.9973\n",
      "Epoch 69/200\n",
      "528/528 [==============================] - 134s 254ms/step - loss: 0.2257 - accuracy: 0.9982 - tumor_dice: 0.6366 - panc_dice: 0.7351 - dice_coeff: 0.9500 - precision_3: 0.9988 - recall_3: 0.9972 - val_loss: 0.2858 - val_accuracy: 0.9971 - val_tumor_dice: 0.4658 - val_panc_dice: 0.6782 - val_dice_coeff: 0.9971 - val_precision_3: 0.9971 - val_recall_3: 0.9971\n",
      "Epoch 70/200\n",
      "528/528 [==============================] - 134s 254ms/step - loss: 0.2309 - accuracy: 0.9981 - tumor_dice: 0.6224 - panc_dice: 0.7345 - dice_coeff: 0.9496 - precision_3: 0.9988 - recall_3: 0.9971 - val_loss: 0.2966 - val_accuracy: 0.9973 - val_tumor_dice: 0.4470 - val_panc_dice: 0.6646 - val_dice_coeff: 0.9973 - val_precision_3: 0.9973 - val_recall_3: 0.9973\n",
      "Epoch 71/200\n",
      "528/528 [==============================] - 134s 254ms/step - loss: 0.2244 - accuracy: 0.9982 - tumor_dice: 0.6356 - panc_dice: 0.7399 - dice_coeff: 0.9504 - precision_3: 0.9988 - recall_3: 0.9972 - val_loss: 0.2925 - val_accuracy: 0.9973 - val_tumor_dice: 0.4617 - val_panc_dice: 0.6620 - val_dice_coeff: 0.9973 - val_precision_3: 0.9973 - val_recall_3: 0.9973\n",
      "Epoch 72/200\n",
      "528/528 [==============================] - 134s 254ms/step - loss: 0.2282 - accuracy: 0.9981 - tumor_dice: 0.6320 - panc_dice: 0.7322 - dice_coeff: 0.9504 - precision_3: 0.9988 - recall_3: 0.9971 - val_loss: 0.3130 - val_accuracy: 0.9972 - val_tumor_dice: 0.3939 - val_panc_dice: 0.6683 - val_dice_coeff: 0.9972 - val_precision_3: 0.9972 - val_recall_3: 0.9972\n",
      "Epoch 73/200\n",
      "528/528 [==============================] - 134s 255ms/step - loss: 0.2282 - accuracy: 0.9981 - tumor_dice: 0.6261 - panc_dice: 0.7378 - dice_coeff: 0.9506 - precision_3: 0.9988 - recall_3: 0.9972 - val_loss: 0.2709 - val_accuracy: 0.9973 - val_tumor_dice: 0.5072 - val_panc_dice: 0.6813 - val_dice_coeff: 0.9973 - val_precision_3: 0.9973 - val_recall_3: 0.9973\n",
      "Epoch 74/200\n",
      "528/528 [==============================] - 134s 254ms/step - loss: 0.2233 - accuracy: 0.9982 - tumor_dice: 0.6363 - panc_dice: 0.7420 - dice_coeff: 0.9508 - precision_3: 0.9988 - recall_3: 0.9972 - val_loss: 0.3109 - val_accuracy: 0.9972 - val_tumor_dice: 0.4323 - val_panc_dice: 0.6362 - val_dice_coeff: 0.9972 - val_precision_3: 0.9972 - val_recall_3: 0.9972\n",
      "Epoch 75/200\n",
      "528/528 [==============================] - 134s 254ms/step - loss: 0.2395 - accuracy: 0.9980 - tumor_dice: 0.6093 - panc_dice: 0.7205 - dice_coeff: 0.9507 - precision_3: 0.9986 - recall_3: 0.9970 - val_loss: 0.3257 - val_accuracy: 0.9971 - val_tumor_dice: 0.3686 - val_panc_dice: 0.6556 - val_dice_coeff: 0.9971 - val_precision_3: 0.9971 - val_recall_3: 0.9971\n",
      "Epoch 76/200\n",
      "528/528 [==============================] - 134s 255ms/step - loss: 0.2275 - accuracy: 0.9981 - tumor_dice: 0.6320 - panc_dice: 0.7341 - dice_coeff: 0.9504 - precision_3: 0.9988 - recall_3: 0.9971 - val_loss: 0.2960 - val_accuracy: 0.9973 - val_tumor_dice: 0.4335 - val_panc_dice: 0.6799 - val_dice_coeff: 0.9973 - val_precision_3: 0.9973 - val_recall_3: 0.9973\n",
      "Epoch 77/200\n",
      "528/528 [==============================] - 134s 254ms/step - loss: 0.2241 - accuracy: 0.9982 - tumor_dice: 0.6348 - panc_dice: 0.7412 - dice_coeff: 0.9509 - precision_3: 0.9988 - recall_3: 0.9972 - val_loss: 0.3164 - val_accuracy: 0.9972 - val_tumor_dice: 0.3978 - val_panc_dice: 0.6541 - val_dice_coeff: 0.9972 - val_precision_3: 0.9972 - val_recall_3: 0.9972\n",
      "Epoch 78/200\n",
      "528/528 [==============================] - 134s 255ms/step - loss: 0.2181 - accuracy: 0.9983 - tumor_dice: 0.6490 - panc_dice: 0.7465 - dice_coeff: 0.9494 - precision_3: 0.9989 - recall_3: 0.9973 - val_loss: 0.2675 - val_accuracy: 0.9974 - val_tumor_dice: 0.5191 - val_panc_dice: 0.6795 - val_dice_coeff: 0.9974 - val_precision_3: 0.9974 - val_recall_3: 0.9974\n",
      "Epoch 79/200\n",
      "528/528 [==============================] - 134s 254ms/step - loss: 0.2132 - accuracy: 0.9983 - tumor_dice: 0.6588 - panc_dice: 0.7500 - dice_coeff: 0.9508 - precision_3: 0.9989 - recall_3: 0.9973 - val_loss: 0.2714 - val_accuracy: 0.9975 - val_tumor_dice: 0.4820 - val_panc_dice: 0.7049 - val_dice_coeff: 0.9975 - val_precision_3: 0.9975 - val_recall_3: 0.9975\n",
      "Epoch 80/200\n",
      "528/528 [==============================] - 134s 254ms/step - loss: 0.2188 - accuracy: 0.9982 - tumor_dice: 0.6466 - panc_dice: 0.7454 - dice_coeff: 0.9506 - precision_3: 0.9989 - recall_3: 0.9972 - val_loss: 0.2974 - val_accuracy: 0.9974 - val_tumor_dice: 0.4394 - val_panc_dice: 0.6695 - val_dice_coeff: 0.9974 - val_precision_3: 0.9974 - val_recall_3: 0.9974\n",
      "Epoch 81/200\n",
      "528/528 [==============================] - 134s 254ms/step - loss: 0.2414 - accuracy: 0.9980 - tumor_dice: 0.5985 - panc_dice: 0.7239 - dice_coeff: 0.9524 - precision_3: 0.9987 - recall_3: 0.9970 - val_loss: 0.3049 - val_accuracy: 0.9972 - val_tumor_dice: 0.4045 - val_panc_dice: 0.6822 - val_dice_coeff: 0.9972 - val_precision_3: 0.9972 - val_recall_3: 0.9972\n",
      "Epoch 82/200\n",
      "528/528 [==============================] - 134s 254ms/step - loss: 0.2276 - accuracy: 0.9982 - tumor_dice: 0.6279 - panc_dice: 0.7379 - dice_coeff: 0.9504 - precision_3: 0.9988 - recall_3: 0.9972 - val_loss: 0.2920 - val_accuracy: 0.9966 - val_tumor_dice: 0.4856 - val_panc_dice: 0.6398 - val_dice_coeff: 0.9966 - val_precision_3: 0.9966 - val_recall_3: 0.9966\n",
      "Epoch 83/200\n",
      "528/528 [==============================] - 134s 254ms/step - loss: 0.2705 - accuracy: 0.9978 - tumor_dice: 0.5383 - panc_dice: 0.6997 - dice_coeff: 0.9495 - precision_3: 0.9985 - recall_3: 0.9968 - val_loss: 0.3732 - val_accuracy: 0.9967 - val_tumor_dice: 0.2673 - val_panc_dice: 0.6145 - val_dice_coeff: 0.9967 - val_precision_3: 0.9967 - val_recall_3: 0.9967\n",
      "Epoch 84/200\n",
      "528/528 [==============================] - 134s 254ms/step - loss: 0.2463 - accuracy: 0.9980 - tumor_dice: 0.5968 - panc_dice: 0.7130 - dice_coeff: 0.9501 - precision_3: 0.9986 - recall_3: 0.9970 - val_loss: 0.3003 - val_accuracy: 0.9974 - val_tumor_dice: 0.4161 - val_panc_dice: 0.6841 - val_dice_coeff: 0.9974 - val_precision_3: 0.9974 - val_recall_3: 0.9974\n",
      "Epoch 85/200\n",
      "528/528 [==============================] - 134s 254ms/step - loss: 0.2218 - accuracy: 0.9982 - tumor_dice: 0.6432 - panc_dice: 0.7400 - dice_coeff: 0.9505 - precision_3: 0.9988 - recall_3: 0.9972 - val_loss: 0.3147 - val_accuracy: 0.9973 - val_tumor_dice: 0.3661 - val_panc_dice: 0.6909 - val_dice_coeff: 0.9973 - val_precision_3: 0.9973 - val_recall_3: 0.9973\n",
      "Epoch 86/200\n",
      "528/528 [==============================] - 134s 254ms/step - loss: 0.2243 - accuracy: 0.9982 - tumor_dice: 0.6361 - panc_dice: 0.7393 - dice_coeff: 0.9507 - precision_3: 0.9988 - recall_3: 0.9972 - val_loss: 0.3434 - val_accuracy: 0.9973 - val_tumor_dice: 0.2964 - val_panc_dice: 0.6748 - val_dice_coeff: 0.9972 - val_precision_3: 0.9973 - val_recall_3: 0.9973\n",
      "Epoch 87/200\n",
      "528/528 [==============================] - 134s 254ms/step - loss: 0.2140 - accuracy: 0.9983 - tumor_dice: 0.6604 - panc_dice: 0.7464 - dice_coeff: 0.9503 - precision_3: 0.9989 - recall_3: 0.9973 - val_loss: 0.2971 - val_accuracy: 0.9975 - val_tumor_dice: 0.4107 - val_panc_dice: 0.6990 - val_dice_coeff: 0.9975 - val_precision_3: 0.9975 - val_recall_3: 0.9975\n",
      "Epoch 88/200\n",
      "528/528 [==============================] - 134s 254ms/step - loss: 0.2135 - accuracy: 0.9983 - tumor_dice: 0.6563 - panc_dice: 0.7511 - dice_coeff: 0.9512 - precision_3: 0.9989 - recall_3: 0.9973 - val_loss: 0.2677 - val_accuracy: 0.9974 - val_tumor_dice: 0.5109 - val_panc_dice: 0.6873 - val_dice_coeff: 0.9974 - val_precision_3: 0.9974 - val_recall_3: 0.9974\n",
      "Epoch 89/200\n",
      "528/528 [==============================] - 134s 254ms/step - loss: 0.2033 - accuracy: 0.9983 - tumor_dice: 0.6840 - panc_dice: 0.7555 - dice_coeff: 0.9496 - precision_3: 0.9990 - recall_3: 0.9974 - val_loss: 0.2903 - val_accuracy: 0.9975 - val_tumor_dice: 0.4434 - val_panc_dice: 0.6868 - val_dice_coeff: 0.9975 - val_precision_3: 0.9975 - val_recall_3: 0.9975\n",
      "Epoch 90/200\n",
      "528/528 [==============================] - 134s 254ms/step - loss: 0.2084 - accuracy: 0.9983 - tumor_dice: 0.6697 - panc_dice: 0.7544 - dice_coeff: 0.9497 - precision_3: 0.9990 - recall_3: 0.9973 - val_loss: 0.2918 - val_accuracy: 0.9973 - val_tumor_dice: 0.4313 - val_panc_dice: 0.6944 - val_dice_coeff: 0.9973 - val_precision_3: 0.9973 - val_recall_3: 0.9973\n",
      "Epoch 91/200\n",
      "528/528 [==============================] - 134s 253ms/step - loss: 0.2076 - accuracy: 0.9983 - tumor_dice: 0.6716 - panc_dice: 0.7549 - dice_coeff: 0.9497 - precision_3: 0.9989 - recall_3: 0.9973 - val_loss: 0.2951 - val_accuracy: 0.9973 - val_tumor_dice: 0.4324 - val_panc_dice: 0.6834 - val_dice_coeff: 0.9973 - val_precision_3: 0.9973 - val_recall_3: 0.9973\n",
      "Epoch 92/200\n",
      "528/528 [==============================] - 134s 254ms/step - loss: 0.2093 - accuracy: 0.9983 - tumor_dice: 0.6643 - panc_dice: 0.7570 - dice_coeff: 0.9500 - precision_3: 0.9990 - recall_3: 0.9973 - val_loss: 0.2800 - val_accuracy: 0.9974 - val_tumor_dice: 0.4666 - val_panc_dice: 0.6944 - val_dice_coeff: 0.9974 - val_precision_3: 0.9974 - val_recall_3: 0.9974\n",
      "Epoch 93/200\n",
      "528/528 [==============================] - 134s 253ms/step - loss: 0.2064 - accuracy: 0.9984 - tumor_dice: 0.6710 - panc_dice: 0.7583 - dice_coeff: 0.9506 - precision_3: 0.9990 - recall_3: 0.9973 - val_loss: 0.3170 - val_accuracy: 0.9972 - val_tumor_dice: 0.3865 - val_panc_dice: 0.6639 - val_dice_coeff: 0.9972 - val_precision_3: 0.9972 - val_recall_3: 0.9972\n",
      "Epoch 94/200\n",
      "528/528 [==============================] - 134s 255ms/step - loss: 0.2044 - accuracy: 0.9984 - tumor_dice: 0.6763 - panc_dice: 0.7601 - dice_coeff: 0.9497 - precision_3: 0.9990 - recall_3: 0.9974 - val_loss: 0.2890 - val_accuracy: 0.9972 - val_tumor_dice: 0.4626 - val_panc_dice: 0.6717 - val_dice_coeff: 0.9972 - val_precision_3: 0.9972 - val_recall_3: 0.9972\n",
      "Epoch 95/200\n",
      "528/528 [==============================] - 134s 254ms/step - loss: 0.2226 - accuracy: 0.9982 - tumor_dice: 0.6377 - panc_dice: 0.7433 - dice_coeff: 0.9504 - precision_3: 0.9988 - recall_3: 0.9972 - val_loss: 0.3212 - val_accuracy: 0.9969 - val_tumor_dice: 0.3735 - val_panc_dice: 0.6642 - val_dice_coeff: 0.9969 - val_precision_3: 0.9969 - val_recall_3: 0.9969\n",
      "Epoch 96/200\n",
      "528/528 [==============================] - 134s 254ms/step - loss: 0.2062 - accuracy: 0.9983 - tumor_dice: 0.6708 - panc_dice: 0.7594 - dice_coeff: 0.9503 - precision_3: 0.9990 - recall_3: 0.9973 - val_loss: 0.3103 - val_accuracy: 0.9974 - val_tumor_dice: 0.3925 - val_panc_dice: 0.6780 - val_dice_coeff: 0.9974 - val_precision_3: 0.9974 - val_recall_3: 0.9974\n",
      "Epoch 97/200\n",
      "528/528 [==============================] - 134s 254ms/step - loss: 0.2084 - accuracy: 0.9983 - tumor_dice: 0.6705 - panc_dice: 0.7527 - dice_coeff: 0.9507 - precision_3: 0.9989 - recall_3: 0.9973 - val_loss: 0.2734 - val_accuracy: 0.9974 - val_tumor_dice: 0.5032 - val_panc_dice: 0.6777 - val_dice_coeff: 0.9974 - val_precision_3: 0.9974 - val_recall_3: 0.9974\n",
      "Epoch 98/200\n",
      "528/528 [==============================] - 134s 254ms/step - loss: 0.2113 - accuracy: 0.9983 - tumor_dice: 0.6607 - panc_dice: 0.7546 - dice_coeff: 0.9499 - precision_3: 0.9989 - recall_3: 0.9973 - val_loss: 0.2995 - val_accuracy: 0.9971 - val_tumor_dice: 0.4737 - val_panc_dice: 0.6291 - val_dice_coeff: 0.9971 - val_precision_3: 0.9971 - val_recall_3: 0.9971\n",
      "Epoch 99/200\n",
      "528/528 [==============================] - 134s 254ms/step - loss: 0.2221 - accuracy: 0.9982 - tumor_dice: 0.6398 - panc_dice: 0.7423 - dice_coeff: 0.9507 - precision_3: 0.9988 - recall_3: 0.9972 - val_loss: 0.3467 - val_accuracy: 0.9971 - val_tumor_dice: 0.3049 - val_panc_dice: 0.6564 - val_dice_coeff: 0.9971 - val_precision_3: 0.9971 - val_recall_3: 0.9971\n",
      "Epoch 100/200\n",
      "528/528 [==============================] - 134s 254ms/step - loss: 0.2098 - accuracy: 0.9983 - tumor_dice: 0.6622 - panc_dice: 0.7569 - dice_coeff: 0.9507 - precision_3: 0.9990 - recall_3: 0.9973 - val_loss: 0.3144 - val_accuracy: 0.9974 - val_tumor_dice: 0.3833 - val_panc_dice: 0.6747 - val_dice_coeff: 0.9974 - val_precision_3: 0.9974 - val_recall_3: 0.9974\n",
      "Epoch 101/200\n",
      "528/528 [==============================] - 134s 254ms/step - loss: 0.1916 - accuracy: 0.9984 - tumor_dice: 0.7071 - panc_dice: 0.7667 - dice_coeff: 0.9506 - precision_3: 0.9991 - recall_3: 0.9974 - val_loss: 0.3212 - val_accuracy: 0.9972 - val_tumor_dice: 0.3528 - val_panc_dice: 0.6848 - val_dice_coeff: 0.9972 - val_precision_3: 0.9972 - val_recall_3: 0.9972\n",
      "Epoch 102/200\n",
      "528/528 [==============================] - 136s 258ms/step - loss: 0.2159 - accuracy: 0.9983 - tumor_dice: 0.6454 - panc_dice: 0.7554 - dice_coeff: 0.9506 - precision_3: 0.9989 - recall_3: 0.9973 - val_loss: 0.3234 - val_accuracy: 0.9973 - val_tumor_dice: 0.3448 - val_panc_dice: 0.6863 - val_dice_coeff: 0.9973 - val_precision_3: 0.9973 - val_recall_3: 0.9973\n",
      "Epoch 103/200\n",
      "161/528 [========>.....................] - ETA: 1:31 - loss: 0.2052 - accuracy: 0.9984 - tumor_dice: 0.6733 - panc_dice: 0.7583 - dice_coeff: 0.9521 - precision_3: 0.9990 - recall_3: 0.9975"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-688492bc6869>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history = fpn.fit(train_generator,\n\u001b[0m\u001b[1;32m      2\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_partial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dev/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dev/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    853\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m         \u001b[0mepoch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dev/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    387\u001b[0m     \"\"\"\n\u001b[1;32m    388\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dev/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_process_logs\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;34m\"\"\"Turns tensors into numpy arrays or Python scalars.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dev/lib/python3.8/site-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dev/lib/python3.8/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 617\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dev/lib/python3.8/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 617\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dev/lib/python3.8/site-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    517\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    520\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dev/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    959\u001b[0m     \"\"\"\n\u001b[1;32m    960\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 961\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    962\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dev/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    925\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 927\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    928\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = fpn.fit(train_generator,\n",
    "          validation_data=(X_val[..., None], y_val),\n",
    "          batch_size=16,\n",
    "          epochs=80,\n",
    "          steps_per_epoch=X_partial.shape[0]//16,\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-91a1ca6e2668>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mh_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "h_df = pd.DataFrame(history.history)\n",
    "plt.plot(h_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "monet.compile(loss=dice_loss, optimizer='adam', metrics=[dice_coeff])\n",
    "unet.compile(loss=dice_loss, optimizer='adam', metrics=[dice_coeff])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "528/528 [==============================] - 104s 196ms/step - loss: 0.9979 - dice_coeff: 0.0021 - val_loss: 0.9977 - val_dice_coeff: 0.0023\n",
      "Epoch 2/200\n",
      "528/528 [==============================] - 104s 197ms/step - loss: 0.9969 - dice_coeff: 0.0031 - val_loss: 0.9964 - val_dice_coeff: 0.0036\n",
      "Epoch 3/200\n",
      "528/528 [==============================] - 104s 197ms/step - loss: 0.9953 - dice_coeff: 0.0047 - val_loss: 0.9947 - val_dice_coeff: 0.0053\n",
      "Epoch 4/200\n",
      "528/528 [==============================] - 101s 192ms/step - loss: 0.9923 - dice_coeff: 0.0077 - val_loss: 0.9930 - val_dice_coeff: 0.0070\n",
      "Epoch 5/200\n",
      "528/528 [==============================] - 100s 190ms/step - loss: 0.9876 - dice_coeff: 0.0124 - val_loss: 0.9901 - val_dice_coeff: 0.0099\n",
      "Epoch 6/200\n",
      "528/528 [==============================] - 100s 190ms/step - loss: 0.9796 - dice_coeff: 0.0204 - val_loss: 0.9840 - val_dice_coeff: 0.0160\n",
      "Epoch 7/200\n",
      "528/528 [==============================] - 100s 190ms/step - loss: 0.9668 - dice_coeff: 0.0332 - val_loss: 0.9633 - val_dice_coeff: 0.0368\n",
      "Epoch 8/200\n",
      "528/528 [==============================] - 100s 190ms/step - loss: 0.9456 - dice_coeff: 0.0544 - val_loss: 0.9525 - val_dice_coeff: 0.0475\n",
      "Epoch 9/200\n",
      "528/528 [==============================] - 100s 190ms/step - loss: 0.9148 - dice_coeff: 0.0853 - val_loss: 0.9349 - val_dice_coeff: 0.0652\n",
      "Epoch 10/200\n",
      "528/528 [==============================] - 100s 190ms/step - loss: 0.8682 - dice_coeff: 0.1320 - val_loss: 0.9353 - val_dice_coeff: 0.0649\n",
      "Epoch 11/200\n",
      "528/528 [==============================] - 101s 192ms/step - loss: 0.8138 - dice_coeff: 0.1865 - val_loss: 0.9226 - val_dice_coeff: 0.0778\n",
      "Epoch 12/200\n",
      "528/528 [==============================] - 102s 194ms/step - loss: 0.7718 - dice_coeff: 0.2286 - val_loss: 0.8941 - val_dice_coeff: 0.1063\n",
      "Epoch 13/200\n",
      "528/528 [==============================] - 103s 195ms/step - loss: 0.7065 - dice_coeff: 0.2940 - val_loss: 0.8634 - val_dice_coeff: 0.1370\n",
      "Epoch 14/200\n",
      "528/528 [==============================] - 103s 194ms/step - loss: 0.6644 - dice_coeff: 0.3361 - val_loss: 0.8585 - val_dice_coeff: 0.1419\n",
      "Epoch 15/200\n",
      "528/528 [==============================] - 102s 194ms/step - loss: 0.6236 - dice_coeff: 0.3770 - val_loss: 0.9373 - val_dice_coeff: 0.0640\n",
      "Epoch 16/200\n",
      "528/528 [==============================] - 102s 193ms/step - loss: 0.5968 - dice_coeff: 0.4039 - val_loss: 0.8775 - val_dice_coeff: 0.1242\n",
      "Epoch 17/200\n",
      "528/528 [==============================] - 101s 191ms/step - loss: 0.5659 - dice_coeff: 0.4348 - val_loss: 0.8525 - val_dice_coeff: 0.1481\n",
      "Epoch 18/200\n",
      "528/528 [==============================] - 101s 190ms/step - loss: 0.5288 - dice_coeff: 0.4719 - val_loss: 0.8401 - val_dice_coeff: 0.1616\n",
      "Epoch 19/200\n",
      "528/528 [==============================] - 101s 191ms/step - loss: 0.5274 - dice_coeff: 0.4734 - val_loss: 0.8263 - val_dice_coeff: 0.1751\n",
      "Epoch 20/200\n",
      "528/528 [==============================] - 100s 190ms/step - loss: 0.5261 - dice_coeff: 0.4747 - val_loss: 0.8599 - val_dice_coeff: 0.1424\n",
      "Epoch 21/200\n",
      "528/528 [==============================] - 100s 190ms/step - loss: 0.4822 - dice_coeff: 0.5185 - val_loss: 0.8378 - val_dice_coeff: 0.1638\n",
      "Epoch 22/200\n",
      "528/528 [==============================] - 100s 190ms/step - loss: 0.4839 - dice_coeff: 0.5169 - val_loss: 0.8638 - val_dice_coeff: 0.1394\n",
      "Epoch 23/200\n",
      "528/528 [==============================] - 100s 190ms/step - loss: 0.4538 - dice_coeff: 0.5470 - val_loss: 0.9118 - val_dice_coeff: 0.0932\n",
      "Epoch 24/200\n",
      "528/528 [==============================] - 100s 190ms/step - loss: 0.4577 - dice_coeff: 0.5431 - val_loss: 0.8593 - val_dice_coeff: 0.1448\n",
      "Epoch 25/200\n",
      "528/528 [==============================] - 100s 190ms/step - loss: 0.4363 - dice_coeff: 0.5645 - val_loss: 0.8569 - val_dice_coeff: 0.1486\n",
      "Epoch 26/200\n",
      "528/528 [==============================] - 100s 190ms/step - loss: 0.4356 - dice_coeff: 0.5652 - val_loss: 0.8831 - val_dice_coeff: 0.1263\n",
      "Epoch 27/200\n",
      "528/528 [==============================] - 100s 190ms/step - loss: 0.4291 - dice_coeff: 0.5717 - val_loss: 0.8586 - val_dice_coeff: 0.1498\n",
      "Epoch 28/200\n",
      "528/528 [==============================] - 101s 191ms/step - loss: 0.4202 - dice_coeff: 0.5807 - val_loss: 0.8422 - val_dice_coeff: 0.1654\n",
      "Epoch 29/200\n",
      "528/528 [==============================] - 102s 193ms/step - loss: 0.4310 - dice_coeff: 0.5698 - val_loss: 0.8653 - val_dice_coeff: 0.1453\n",
      "Epoch 30/200\n",
      "528/528 [==============================] - 104s 197ms/step - loss: 0.4057 - dice_coeff: 0.5952 - val_loss: 0.8699 - val_dice_coeff: 0.1434\n",
      "Epoch 31/200\n",
      "528/528 [==============================] - 105s 200ms/step - loss: 0.3936 - dice_coeff: 0.6073 - val_loss: 0.8959 - val_dice_coeff: 0.1186\n",
      "Epoch 32/200\n",
      "528/528 [==============================] - 104s 197ms/step - loss: 0.3881 - dice_coeff: 0.6128 - val_loss: 0.8585 - val_dice_coeff: 0.1575\n",
      "Epoch 33/200\n",
      "528/528 [==============================] - 102s 194ms/step - loss: 0.4278 - dice_coeff: 0.5732 - val_loss: 0.8731 - val_dice_coeff: 0.1487\n",
      "Epoch 34/200\n",
      "528/528 [==============================] - 103s 195ms/step - loss: 0.3855 - dice_coeff: 0.6156 - val_loss: 0.8641 - val_dice_coeff: 0.1544\n",
      "Epoch 35/200\n",
      "528/528 [==============================] - 101s 192ms/step - loss: 0.3885 - dice_coeff: 0.6125 - val_loss: 0.8458 - val_dice_coeff: 0.1784\n",
      "Epoch 36/200\n",
      "528/528 [==============================] - 100s 190ms/step - loss: 0.3623 - dice_coeff: 0.6386 - val_loss: 0.8936 - val_dice_coeff: 0.1369\n",
      "Epoch 37/200\n",
      "528/528 [==============================] - 101s 190ms/step - loss: 0.3669 - dice_coeff: 0.6341 - val_loss: 0.8613 - val_dice_coeff: 0.1588\n",
      "Epoch 38/200\n",
      "528/528 [==============================] - 106s 201ms/step - loss: 0.3632 - dice_coeff: 0.6377 - val_loss: 0.9325 - val_dice_coeff: 0.1197\n",
      "Epoch 39/200\n",
      "528/528 [==============================] - 104s 197ms/step - loss: 0.3608 - dice_coeff: 0.6401 - val_loss: 0.8041 - val_dice_coeff: 0.2244\n",
      "Epoch 40/200\n",
      "528/528 [==============================] - 104s 196ms/step - loss: 0.3678 - dice_coeff: 0.6333 - val_loss: 0.8822 - val_dice_coeff: 0.1675\n",
      "Epoch 41/200\n",
      "528/528 [==============================] - 103s 195ms/step - loss: 0.3409 - dice_coeff: 0.6599 - val_loss: 0.8665 - val_dice_coeff: 0.1675\n",
      "Epoch 42/200\n",
      "528/528 [==============================] - 100s 190ms/step - loss: 0.3487 - dice_coeff: 0.6524 - val_loss: 0.8876 - val_dice_coeff: 0.1852\n",
      "Epoch 43/200\n",
      "528/528 [==============================] - 100s 190ms/step - loss: 0.3450 - dice_coeff: 0.6558 - val_loss: 0.8995 - val_dice_coeff: 0.1693\n",
      "Epoch 44/200\n",
      "528/528 [==============================] - 102s 193ms/step - loss: 0.3434 - dice_coeff: 0.6577 - val_loss: 0.8228 - val_dice_coeff: 0.2387\n",
      "Epoch 45/200\n",
      "528/528 [==============================] - 100s 190ms/step - loss: 0.3424 - dice_coeff: 0.6586 - val_loss: 0.8654 - val_dice_coeff: 0.1963\n",
      "Epoch 46/200\n",
      "528/528 [==============================] - 104s 197ms/step - loss: 0.3461 - dice_coeff: 0.6550 - val_loss: 0.8971 - val_dice_coeff: 0.1556\n",
      "Epoch 47/200\n",
      "528/528 [==============================] - 104s 196ms/step - loss: 0.3411 - dice_coeff: 0.6608 - val_loss: 0.8657 - val_dice_coeff: 0.1804\n",
      "Epoch 48/200\n",
      "528/528 [==============================] - 106s 202ms/step - loss: 0.3554 - dice_coeff: 0.6464 - val_loss: 0.8244 - val_dice_coeff: 0.2240\n",
      "Epoch 49/200\n",
      "528/528 [==============================] - 103s 194ms/step - loss: 0.3312 - dice_coeff: 0.6700 - val_loss: 0.8617 - val_dice_coeff: 0.2520\n",
      "Epoch 50/200\n",
      "528/528 [==============================] - 128s 243ms/step - loss: 0.3152 - dice_coeff: 0.6859 - val_loss: 0.8554 - val_dice_coeff: 0.2166\n",
      "Epoch 51/200\n",
      "528/528 [==============================] - 198s 375ms/step - loss: 0.3276 - dice_coeff: 0.6737 - val_loss: 0.8815 - val_dice_coeff: 0.1684\n",
      "Epoch 52/200\n",
      "528/528 [==============================] - 207s 393ms/step - loss: 0.3164 - dice_coeff: 0.6856 - val_loss: 0.8618 - val_dice_coeff: 0.2343\n",
      "Epoch 53/200\n",
      "528/528 [==============================] - 192s 363ms/step - loss: 0.3201 - dice_coeff: 0.6815 - val_loss: 0.8643 - val_dice_coeff: 0.1887\n",
      "Epoch 54/200\n",
      "528/528 [==============================] - 102s 194ms/step - loss: 0.3346 - dice_coeff: 0.6664 - val_loss: 0.8388 - val_dice_coeff: 0.2387\n",
      "Epoch 55/200\n",
      "528/528 [==============================] - 115s 218ms/step - loss: 0.3186 - dice_coeff: 0.6828 - val_loss: 0.8543 - val_dice_coeff: 0.1990\n",
      "Epoch 56/200\n",
      "528/528 [==============================] - 146s 276ms/step - loss: 0.3096 - dice_coeff: 0.6916 - val_loss: 0.8640 - val_dice_coeff: 0.2450\n",
      "Epoch 57/200\n",
      "528/528 [==============================] - 149s 282ms/step - loss: 0.3097 - dice_coeff: 0.6914 - val_loss: 0.8625 - val_dice_coeff: 0.2645\n",
      "Epoch 58/200\n",
      "528/528 [==============================] - 142s 269ms/step - loss: 0.3114 - dice_coeff: 0.6898 - val_loss: 0.8604 - val_dice_coeff: 0.1949\n",
      "Epoch 59/200\n",
      "528/528 [==============================] - 102s 193ms/step - loss: 0.3132 - dice_coeff: 0.6878 - val_loss: 0.9181 - val_dice_coeff: 0.1946\n",
      "Epoch 60/200\n",
      "528/528 [==============================] - 102s 193ms/step - loss: 0.3042 - dice_coeff: 0.6966 - val_loss: 0.8993 - val_dice_coeff: 0.2154\n",
      "Epoch 61/200\n",
      "528/528 [==============================] - 103s 195ms/step - loss: 0.3001 - dice_coeff: 0.7009 - val_loss: 0.8860 - val_dice_coeff: 0.2570\n",
      "Epoch 62/200\n",
      "528/528 [==============================] - 106s 200ms/step - loss: 0.2965 - dice_coeff: 0.7045 - val_loss: 0.8272 - val_dice_coeff: 0.2601\n",
      "Epoch 63/200\n",
      "528/528 [==============================] - 102s 194ms/step - loss: 0.3060 - dice_coeff: 0.6950 - val_loss: 0.8452 - val_dice_coeff: 0.2162\n",
      "Epoch 64/200\n",
      "528/528 [==============================] - 104s 197ms/step - loss: 0.3115 - dice_coeff: 0.6897 - val_loss: 0.9129 - val_dice_coeff: 0.2063\n",
      "Epoch 65/200\n",
      "528/528 [==============================] - 108s 204ms/step - loss: 0.2993 - dice_coeff: 0.7033 - val_loss: 0.8675 - val_dice_coeff: 0.2279\n",
      "Epoch 66/200\n",
      "528/528 [==============================] - 110s 208ms/step - loss: 0.2876 - dice_coeff: 0.7137 - val_loss: 0.8287 - val_dice_coeff: 0.2899\n",
      "Epoch 67/200\n",
      "528/528 [==============================] - 108s 204ms/step - loss: 0.3054 - dice_coeff: 0.6965 - val_loss: 0.9263 - val_dice_coeff: 0.1653\n",
      "Epoch 68/200\n",
      "528/528 [==============================] - 107s 203ms/step - loss: 0.3046 - dice_coeff: 0.6965 - val_loss: 0.8494 - val_dice_coeff: 0.2461\n",
      "Epoch 69/200\n",
      "528/528 [==============================] - 100s 190ms/step - loss: 0.2919 - dice_coeff: 0.7100 - val_loss: 0.8645 - val_dice_coeff: 0.2553\n",
      "Epoch 70/200\n",
      "528/528 [==============================] - 106s 202ms/step - loss: 0.2840 - dice_coeff: 0.7170 - val_loss: 0.8338 - val_dice_coeff: 0.2863\n",
      "Epoch 71/200\n",
      "528/528 [==============================] - 106s 201ms/step - loss: 0.2972 - dice_coeff: 0.7046 - val_loss: 0.8822 - val_dice_coeff: 0.2101\n",
      "Epoch 72/200\n",
      "528/528 [==============================] - 106s 201ms/step - loss: 0.2824 - dice_coeff: 0.7188 - val_loss: 0.8836 - val_dice_coeff: 0.2439\n",
      "Epoch 73/200\n",
      "528/528 [==============================] - 101s 191ms/step - loss: 0.2947 - dice_coeff: 0.7063 - val_loss: 0.8486 - val_dice_coeff: 0.3139\n",
      "Epoch 74/200\n",
      "528/528 [==============================] - 102s 192ms/step - loss: 0.2853 - dice_coeff: 0.7166 - val_loss: 0.8527 - val_dice_coeff: 0.2120\n",
      "Epoch 75/200\n",
      "528/528 [==============================] - 107s 202ms/step - loss: 0.2895 - dice_coeff: 0.7116 - val_loss: 0.8447 - val_dice_coeff: 0.3332\n",
      "Epoch 76/200\n",
      "528/528 [==============================] - 104s 198ms/step - loss: 0.2684 - dice_coeff: 0.7334 - val_loss: 0.9172 - val_dice_coeff: 0.2409\n",
      "Epoch 77/200\n",
      "528/528 [==============================] - 106s 201ms/step - loss: 0.2862 - dice_coeff: 0.7161 - val_loss: 0.8228 - val_dice_coeff: 0.2712\n",
      "Epoch 78/200\n",
      "528/528 [==============================] - 100s 190ms/step - loss: 0.2835 - dice_coeff: 0.7209 - val_loss: 0.8947 - val_dice_coeff: 0.2358\n",
      "Epoch 79/200\n",
      "528/528 [==============================] - 102s 193ms/step - loss: 0.2800 - dice_coeff: 0.7211 - val_loss: 0.9265 - val_dice_coeff: 0.2096\n",
      "Epoch 80/200\n",
      "528/528 [==============================] - 110s 208ms/step - loss: 0.2713 - dice_coeff: 0.7303 - val_loss: 0.8640 - val_dice_coeff: 0.2601\n",
      "Epoch 81/200\n",
      "528/528 [==============================] - 110s 208ms/step - loss: 0.2972 - dice_coeff: 0.7039 - val_loss: 0.8329 - val_dice_coeff: 0.3226\n",
      "Epoch 82/200\n",
      "528/528 [==============================] - 110s 208ms/step - loss: 0.2722 - dice_coeff: 0.7295 - val_loss: 0.8676 - val_dice_coeff: 0.1980\n",
      "Epoch 83/200\n",
      "528/528 [==============================] - 110s 208ms/step - loss: 0.2784 - dice_coeff: 0.7227 - val_loss: 0.8478 - val_dice_coeff: 0.2235\n",
      "Epoch 84/200\n",
      "528/528 [==============================] - 110s 208ms/step - loss: 0.2759 - dice_coeff: 0.7255 - val_loss: 0.8200 - val_dice_coeff: 0.3066\n",
      "Epoch 85/200\n",
      "528/528 [==============================] - 110s 209ms/step - loss: 0.2635 - dice_coeff: 0.7378 - val_loss: 0.8567 - val_dice_coeff: 0.2418\n",
      "Epoch 86/200\n",
      "528/528 [==============================] - 112s 212ms/step - loss: 0.2751 - dice_coeff: 0.7262 - val_loss: 0.8602 - val_dice_coeff: 0.2358\n",
      "Epoch 87/200\n",
      "528/528 [==============================] - 111s 211ms/step - loss: 0.2687 - dice_coeff: 0.7322 - val_loss: 0.8537 - val_dice_coeff: 0.2735\n",
      "Epoch 88/200\n",
      "528/528 [==============================] - 112s 212ms/step - loss: 0.2698 - dice_coeff: 0.7323 - val_loss: 0.8281 - val_dice_coeff: 0.2989\n",
      "Epoch 89/200\n",
      "528/528 [==============================] - 108s 205ms/step - loss: 0.2512 - dice_coeff: 0.7495 - val_loss: 0.7979 - val_dice_coeff: 0.2985\n",
      "Epoch 90/200\n",
      "528/528 [==============================] - 100s 190ms/step - loss: 0.2652 - dice_coeff: 0.7358 - val_loss: 0.8327 - val_dice_coeff: 0.2969\n",
      "Epoch 91/200\n",
      "528/528 [==============================] - 100s 190ms/step - loss: 0.2540 - dice_coeff: 0.7469 - val_loss: 0.8150 - val_dice_coeff: 0.2930\n",
      "Epoch 92/200\n",
      "528/528 [==============================] - 100s 190ms/step - loss: 0.2565 - dice_coeff: 0.7444 - val_loss: 0.8331 - val_dice_coeff: 0.2642\n",
      "Epoch 93/200\n",
      "528/528 [==============================] - 100s 190ms/step - loss: 0.2437 - dice_coeff: 0.7579 - val_loss: 0.8505 - val_dice_coeff: 0.2808\n",
      "Epoch 94/200\n",
      "528/528 [==============================] - 100s 190ms/step - loss: 0.2654 - dice_coeff: 0.7370 - val_loss: 0.8399 - val_dice_coeff: 0.2604\n",
      "Epoch 95/200\n",
      "528/528 [==============================] - 100s 190ms/step - loss: 0.2683 - dice_coeff: 0.7328 - val_loss: 0.8188 - val_dice_coeff: 0.2787\n",
      "Epoch 96/200\n",
      "528/528 [==============================] - 100s 190ms/step - loss: 0.2526 - dice_coeff: 0.7497 - val_loss: 0.8341 - val_dice_coeff: 0.2713\n",
      "Epoch 97/200\n",
      "528/528 [==============================] - 101s 191ms/step - loss: 0.2479 - dice_coeff: 0.7547 - val_loss: 0.8557 - val_dice_coeff: 0.2445\n",
      "Epoch 98/200\n",
      "  1/528 [..............................] - ETA: 0s - loss: 0.1889 - dice_coeff: 0.8114"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-a078c18d20de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history = monet.fit(\n\u001b[0m\u001b[1;32m      2\u001b[0m           \u001b[0mX_partial\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m           \u001b[0my_partial_tumor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val_tumor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_partial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mb_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dev/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dev/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    853\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m         \u001b[0mepoch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dev/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    387\u001b[0m     \"\"\"\n\u001b[1;32m    388\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dev/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_process_logs\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;34m\"\"\"Turns tensors into numpy arrays or Python scalars.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dev/lib/python3.8/site-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dev/lib/python3.8/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 617\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dev/lib/python3.8/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 617\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dev/lib/python3.8/site-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    517\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    520\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dev/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    959\u001b[0m     \"\"\"\n\u001b[1;32m    960\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 961\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    962\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dev/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    925\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 927\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    928\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = monet.fit(\n",
    "          X_partial[..., None],\n",
    "          y_partial_tumor[..., None],\n",
    "          validation_data=(X_val[..., None], y_val_tumor[..., None]),\n",
    "          steps_per_epoch=X_partial.shape[0]//b_size,\n",
    "          epochs=200,\n",
    "          callbacks=[],\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8448, 256, 256)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_partial_tumor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - 13s 99ms/step - loss: 0.6052 - accuracy: 0.9970 - tumor_dice: 0.2599 - panc_dice: 0.6444 - precision_7: 0.9961 - recall_7: 0.9976\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6052348017692566,\n",
       " 0.9969928860664368,\n",
       " 0.2599358558654785,\n",
       " 0.644449770450592,\n",
       " 0.9961434602737427,\n",
       " 0.9976320266723633]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpn.evaluate(X_test[..., None], y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - 15s 118ms/step - loss: 0.0030 - accuracy: 0.9970 - tumor_dice: 0.1973 - panc_dice: 0.6296 - precision: 0.9970 - recall: 0.9970\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0029794713482260704,\n",
       " 0.9970209002494812,\n",
       " 0.19725310802459717,\n",
       " 0.629561722278595,\n",
       " 0.9970208406448364,\n",
       " 0.9970208406448364]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monet.evaluate(X_test[..., None], y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = monet.predict(X_partial[..., None], batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10,20):\n",
    "    print(\"pred\")\n",
    "    plt.imshow(y_pred[i, ..., 1])\n",
    "    plt.show()\n",
    "    print(\"actual\")\n",
    "    plt.imshow(y_partial[i, ...,1])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}